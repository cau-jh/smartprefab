import pandas as pd
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.cluster import AgglomerativeClustering

# -----------------------
# ì„¤ì •: í—ˆìš©í•  ê°œë… í‚¤ì›Œë“œ
# -----------------------
ALLOWED_KEYWORDS = [
    "construct",
    "structure",
    "structural",
    "bridge",
    "precast",
    "prefab",
    "concrete",
    "digital",
    "twin",
    "monitor",
    "health",
    "ai",
    "learning",
    "automation",
    "3d",
    "printing",
]

def is_allowed(concept):
    c = concept.lower()
    return any(k in c for k in ALLOWED_KEYWORDS)

# -----------------------
# Load data
# -----------------------
concepts = pd.read_csv("paper_concepts.csv")
works = pd.read_csv("orcid_works.csv")

# -----------------------
# ğŸ”¥ í•µì‹¬: ê°œë… í•„í„°ë§
# -----------------------
concepts = concepts[concepts["concept_name"].apply(is_allowed)]

print(f"âœ… Filtered concepts: {len(concepts)} rows")

# -----------------------
# Concept vector
# -----------------------
pivot = concepts.pivot_table(
    index="work_id",
    columns="concept_name",
    values="score",
    fill_value=0
)

# ì•ˆì „ ì¥ì¹˜
if len(pivot) < 2:
    raise ValueError("âŒ ë…¼ë¬¸ ìˆ˜ê°€ ë„ˆë¬´ ì ì–´ í´ëŸ¬ìŠ¤í„°ë§ ë¶ˆê°€")

# -----------------------
# Similarity & Distance
# -----------------------
sim = cosine_similarity(pivot.values)
dist = 1 - sim

# -----------------------
# Clustering
# -----------------------
n_topics = min(4, len(pivot))  # ìš°ë¦¬ ì—°êµ¬ì‹¤ ê·œëª¨ì— ë§ê²Œ

model = AgglomerativeClustering(
    n_clusters=n_topics,
    metric="precomputed",
    linkage="average"
)

labels = model.fit_predict(dist)

# -----------------------
# Output 1: paper_topics.csv
# -----------------------
paper_topics = pd.DataFrame({
    "work_id": pivot.index,
    "topic_id": labels
}).merge(
    works[["work_id", "title"]],
    on="work_id",
    how="left"
)

paper_topics.to_csv(
    "paper_topics.csv",
    index=False,
    encoding="utf-8-sig"
)

# -----------------------
# Output 2: topic_summary.csv
# -----------------------
topic_summary = (
    concepts.merge(paper_topics, on="work_id")
    .groupby(["topic_id", "concept_name"])
    .score.mean()
    .reset_index()
    .sort_values(["topic_id", "score"], ascending=[True, False])
)

topic_summary = topic_summary.groupby("topic_id").head(5)

topic_summary.to_csv(
    "topic_summary.csv",
    index=False,
    encoding="utf-8-sig"
)

print("âœ… Aì•ˆ ì ìš© ì™„ë£Œ: paper_topics.csv / topic_summary.csv ì¬ìƒì„±")
